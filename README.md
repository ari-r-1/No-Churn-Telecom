# ğŸ“Œ No-Churn-Telecom: Customer Churn Prediction  

## ğŸ“– Project Overview  
The **No-Churn-Telecom** project predicts customer churn in the telecom sector using machine learning techniques.  
With a dataset of **4,617 customer records**, the goal is to identify customers likely to leave and provide business insights for retention strategies.  

---

## ğŸ—‚ Dataset  
- **Size**: 4,617 customer records  
- **Features**: Call durations, number of calls, international plan, voicemail plan, etc.  
- **Target**: `Churn` (Yes/No)  

---

## âš™ï¸ Methodology  
1. **Data Preprocessing** â€“ Handling missing values, encoding categorical variables, scaling features.  
2. **Exploratory Data Analysis (EDA)** â€“ Understanding churn distribution, correlations, and feature importance.  
3. **Modeling** â€“ Applied multiple algorithms:  
   - Logistic Regression  
   - Random Forest  
   - Gradient Boosting (XGBoost, LGBM)  
4. **Fine-Tuning** â€“ Hyperparameter tuning for optimal performance.  
5. **Evaluation** â€“ Accuracy, precision, recall, F1-score, ROC-AUC.  

---

## ğŸ“Š Results  
- **Best Model**: Light Gradient Boosting Machine (LGBM)  
- **Accuracy**: **97.18%**  
- **Insights**: International plans, call usage, and voicemail are strong churn predictors.  

---

## ğŸ’¡ Business Impact  
- Helps telecom companies **identify high-risk customers**.  
- Supports **data-driven retention strategies**.  
- Reduces revenue loss by minimizing churn.  

---

## ğŸ›  Tools & Technologies  
- **Python**  
- **Pandas, NumPy** â€“ Data handling  
- **Matplotlib, Seaborn** â€“ Data visualization  
- **Scikit-learn** â€“ Machine learning models  
- **LightGBM, XGBoost** â€“ Gradient boosting algorithms  

---
## ğŸ“ˆ Workflow

1. **Exploratory Data Analysis (EDA)**  
   - Distribution of features  
   - Correlation analysis  
   - Handling missing values & class imbalance  

2. **Data Preprocessing**  
   - Encoding categorical variables  
   - Feature scaling  
   - Handling imbalanced classes (SMOTE/undersampling)  

3. **Modeling**  
   - Logistic Regression  
   - Random Forest  
   - XGBoost  
   - Support Vector Machine  

4. **Model Evaluation**  
   - Train-test split & cross-validation  
   - Metrics: Accuracy, Precision, Recall, F1-score, ROC-AUC  
   - Comparison of models  

5. **Insights & Business Value**  
   - Identifying customer segments most likely to subscribe  
   - Recommendations for improving campaign targeting  

---

## ğŸ“Š Visualizations

- Feature importance plots  
- Correlation heatmaps  
- ROC & Precision-Recall curves  
- Confusion matrices  

---

## ğŸ’¡ Future Improvements

- Deploy as a Flask/Django web app  
- Integrate with real-time campaign data  
- Use deep learning models for comparison  
- Hyperparameter optimization with Optuna  

---

## ğŸ¤ Contributing

**Ari R.**  
_Data Scientist_  
ğŸ”— [GitHub](https://github.com/ari-r-1) | ğŸ“§ ariranalyst@gmail.com

---

âœ¨ Developed with passion for Data Science & Machine Learning.
"# No-Churn-Telecom" "# No-Churn-Telecom" 
